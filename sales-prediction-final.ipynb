{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Mart Sales Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Source:__ Data science competition at [Analytics Vidhya](https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes information about 1559 products that were sold in 10 different stores in 2013. There are various attributes that are associated to each product and store. Our goals is to train a predictive model which can predict the future sales of products given both store and item attributes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "variables   : [['Item_Identifier'],\n",
    "               ['Item_Weight'],\n",
    "               ['Item_Fat_Content'],\n",
    "               ['Item_Visibility'],\n",
    "               ['Item_Type'],\n",
    "               ['Item_MRP'],\n",
    "               ['Outlet_Identifier'],\n",
    "               ['Outlet_Establishment_Year'],\n",
    "               ['Outlet_Size'],\n",
    "               ['Outlet_Location_Type'],\n",
    "               ['Outlet_Type'],\n",
    "               ['Item_Outlet_Sales']]\n",
    "\n",
    "train shape : 8523 rows, 12 columns  (the last attribute is the target)\n",
    "test shape  : 5681 rows, 11 columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data science problem:** Predict product sales based on product and store attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps of our data science process:\n",
    "\n",
    "1. Set the research goal: Find out the future sales of products in a particular store\n",
    "2. Acquire data: Data is available as part of a data science competition\n",
    "3. Explore data: Basic data exploration\n",
    "4. Plan strategy: Determine strategies to treat missing data, engineer new features\n",
    "5. Build pipeline: Build an ML pipeline\n",
    "6. Build model: Compare different predictive models\n",
    "7. Present: Report the results\n",
    "\n",
    "- Resources\n",
    "- Link to GitHub repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: I will use a Machine Learning pipeline using the Scikit-learn library. Pipelines allow code reuse and consistence in handling training and test sets.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Research goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to be able to predict the sales of certain products in particular stores. Such an information is very valuable since we can:\n",
    "- Notice the fluctuations in product sales and we take actions\n",
    "- Divert products to stores where they are more popular\n",
    "- Figure out what attributes are associated with popular products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Acquire data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and test data were downloaded to the working directory from the competition's website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train-file.csv\")\n",
    "test = pd.read_csv(\"test-file.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine file content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8523, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['Item_Identifier'],\n",
       "       ['Item_Weight'],\n",
       "       ['Item_Fat_Content'],\n",
       "       ['Item_Visibility'],\n",
       "       ['Item_Type'],\n",
       "       ['Item_MRP'],\n",
       "       ['Outlet_Identifier'],\n",
       "       ['Outlet_Establishment_Year'],\n",
       "       ['Outlet_Size'],\n",
       "       ['Outlet_Location_Type'],\n",
       "       ['Outlet_Type'],\n",
       "       ['Item_Outlet_Sales']], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "display(train.columns.values.reshape((12,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 item (product) attributes, and 5 outlet (store) attibutes. Note that the *Item_Outlet_Sales* is the target variable.\n",
    "\n",
    "The attribute names are fairly self explanatory. The *Item_Identifier* has unique items for each product, while the *Outlet_Identifier* holds codes regarding the outlets.\n",
    "\n",
    "Let's take a look at the first few lines to have a general idea about the data types and values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat         0.016047   \n",
       "1           DRC01         5.92          Regular         0.019278   \n",
       "2           FDN15        17.50          Low Fat         0.016760   \n",
       "3           FDX07        19.20          Regular         0.000000   \n",
       "4           NCD19         8.93          Low Fat         0.000000   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                  Dairy  249.8092            OUT049   \n",
       "1            Soft Drinks   48.2692            OUT018   \n",
       "2                   Meat  141.6180            OUT049   \n",
       "3  Fruits and Vegetables  182.0950            OUT010   \n",
       "4              Household   53.8614            OUT013   \n",
       "\n",
       "   Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                       1999      Medium               Tier 1   \n",
       "1                       2009      Medium               Tier 3   \n",
       "2                       1999      Medium               Tier 1   \n",
       "3                       1998         NaN               Tier 3   \n",
       "4                       1987        High               Tier 3   \n",
       "\n",
       "         Outlet_Type  Item_Outlet_Sales  \n",
       "0  Supermarket Type1          3735.1380  \n",
       "1  Supermarket Type2           443.4228  \n",
       "2  Supermarket Type1          2097.2700  \n",
       "3      Grocery Store           732.3800  \n",
       "4  Supermarket Type1           994.7052  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, I can see that some of the variables are categorical. A categorical variable's data type is `object`, whereas numerical variables can be `float64` or `int64`. Let's see which variables are categorical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Variables:\n",
      "----------------------\n",
      "Item_Identifier\n",
      "Item_Fat_Content\n",
      "Item_Type\n",
      "Outlet_Identifier\n",
      "Outlet_Size\n",
      "Outlet_Location_Type\n",
      "Outlet_Type\n"
     ]
    }
   ],
   "source": [
    "print('Categorical Variables:')\n",
    "print('----------------------')\n",
    "for x in train.dtypes.index:\n",
    "    if train.dtypes[x]=='object':\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I continue to examine data. One of the best ways of seeing the big picture is looking at the number of unique values in a variable and if it has any missing values. I am going to write a custom function that reports that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_summary(df):\n",
    "    df1 = df.count()\n",
    "    df2 = df.apply(lambda x: sum(x.isnull()))  # missing values\n",
    "    df3 = df.apply(lambda x: len(x.unique()))  # missing values\n",
    "\n",
    "    dfx = pd.concat([df1, df2, df3], axis=1)\n",
    "    dfx.columns = ['count', 'NaN', 'Unique']\n",
    "    print(dfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           count   NaN  Unique\n",
      "Item_Identifier             8523     0    1559\n",
      "Item_Weight                 7060  1463     416\n",
      "Item_Fat_Content            8523     0       5\n",
      "Item_Visibility             8523     0    7880\n",
      "Item_Type                   8523     0      16\n",
      "Item_MRP                    8523     0    5938\n",
      "Outlet_Identifier           8523     0      10\n",
      "Outlet_Establishment_Year   8523     0       9\n",
      "Outlet_Size                 6113  2410       4\n",
      "Outlet_Location_Type        8523     0       3\n",
      "Outlet_Type                 8523     0       4\n",
      "Item_Outlet_Sales           8523     0    3493\n"
     ]
    }
   ],
   "source": [
    "my_summary(train)  # Details variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above summary, I immediately notice two things:\n",
    "1. *Item_Weight* and *Outlet_Size* needs to be treated for missing values\n",
    "2. *Item_Identifier* is a categorical variable, but it has too many unique values. I have to find a way to either transform it to a numerical variable, or somehow reduce its dimensions if I want to use it in my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I haven't started cleaning the data yet. I need to take a closer look at the categorical variables to see if they need any treatment before moving on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FDW13    10\n",
      "FDG33    10\n",
      "FDX20     9\n",
      "FDV60     9\n",
      "NCQ06     9\n",
      "         ..\n",
      "FDC23     1\n",
      "FDO33     1\n",
      "FDN52     1\n",
      "DRF48     1\n",
      "FDE52     1\n",
      "Name: Item_Identifier, Length: 1559, dtype: int64\n",
      "---\n",
      "Low Fat    5089\n",
      "Regular    2889\n",
      "LF          316\n",
      "reg         117\n",
      "low fat     112\n",
      "Name: Item_Fat_Content, dtype: int64\n",
      "---\n",
      "Fruits and Vegetables    1232\n",
      "Snack Foods              1200\n",
      "Household                 910\n",
      "Frozen Foods              856\n",
      "Dairy                     682\n",
      "Canned                    649\n",
      "Baking Goods              648\n",
      "Health and Hygiene        520\n",
      "Soft Drinks               445\n",
      "Meat                      425\n",
      "Breads                    251\n",
      "Hard Drinks               214\n",
      "Others                    169\n",
      "Starchy Foods             148\n",
      "Breakfast                 110\n",
      "Seafood                    64\n",
      "Name: Item_Type, dtype: int64\n",
      "---\n",
      "OUT027    935\n",
      "OUT013    932\n",
      "OUT035    930\n",
      "OUT049    930\n",
      "OUT046    930\n",
      "OUT045    929\n",
      "OUT018    928\n",
      "OUT017    926\n",
      "OUT010    555\n",
      "OUT019    528\n",
      "Name: Outlet_Identifier, dtype: int64\n",
      "---\n",
      "Medium    2793\n",
      "Small     2388\n",
      "High       932\n",
      "Name: Outlet_Size, dtype: int64\n",
      "---\n",
      "Tier 3    3350\n",
      "Tier 2    2785\n",
      "Tier 1    2388\n",
      "Name: Outlet_Location_Type, dtype: int64\n",
      "---\n",
      "Supermarket Type1    5577\n",
      "Grocery Store        1083\n",
      "Supermarket Type3     935\n",
      "Supermarket Type2     928\n",
      "Name: Outlet_Type, dtype: int64\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "cat_var = ['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', \n",
    "               'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n",
    "\n",
    "for col in cat_var:\n",
    "    print(train[col].value_counts())\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I can make two important observations:\n",
    "1. It looks like *Item_Identifier* starts with a 2-letter code and most items start with the same code. We can extract this information and use it in our model.\n",
    "2. *Item_Fat_Content* has 5 unique values, but it looks like some of them represent the same thing. We need to fix that as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a look at the numerical variables to see if they need any treatment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.300</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.920</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.500</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.4008</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.650</td>\n",
       "      <td>0.012741</td>\n",
       "      <td>57.6588</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.127470</td>\n",
       "      <td>107.7622</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.200</td>\n",
       "      <td>0.016687</td>\n",
       "      <td>96.9726</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.200</td>\n",
       "      <td>0.094450</td>\n",
       "      <td>187.8214</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Visibility  Item_MRP  Outlet_Establishment_Year\n",
       "0        9.300         0.016047  249.8092                       1999\n",
       "1        5.920         0.019278   48.2692                       2009\n",
       "2       17.500         0.016760  141.6180                       1999\n",
       "3       19.200         0.000000  182.0950                       1998\n",
       "4        8.930         0.000000   53.8614                       1987\n",
       "5       10.395         0.000000   51.4008                       2009\n",
       "6       13.650         0.012741   57.6588                       1987\n",
       "7          NaN         0.127470  107.7622                       1985\n",
       "8       16.200         0.016687   96.9726                       2002\n",
       "9       19.200         0.094450  187.8214                       2007"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_var = ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']\n",
    "\n",
    "train[num_var].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two things:\n",
    "1. *Item_Visibility* represent the percent display area of a product. Since all products are visible to some degree, having a 0.0 visibility value doesn't make sense. These entries are probably missing. So, we have to find a way to replace these zeros with more meaningful values.\n",
    "2. Using outlet's age instead of *Outlet_Establishment_Year* feels more natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Action Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, I finally have a plan of action. My data cleaning process will be as follows:\n",
    "1. Missing data treatment for\n",
    "    - *Item_Weight*\n",
    "    - *Item_Visibility*\n",
    "    - *Outlet_Size*\n",
    "2. Feature engineering\n",
    "    - Create an extra feature using codes in the *Item_Identifier*\n",
    "    - Fix overlapping namings in *Item_Fat_Content*\n",
    "    - Use establishment's age instead of *Outlet_Establishment_Year*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One very important note: I am NOT going to include the TEST set in the data cleaning process of the TRAINING set. Once I establish the rules in the TRAINING set, I will use the same rules to treat the TEST set.**\n",
    "\n",
    "**For example, when treating the missing Item_Weight values the the TEST set, I am NOT going to look at the weight data in the TEST set. Instead, I am going to fill the missing values using the weight data in the TRAINING set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Missing data treatment - *Item_Weight*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My approach is simple: If the weight is missing in a particular row, find the *Item_Identifier* in that row. Then, scan the whole data to see if other items with the same identifier have entries in the weight section. If yes, take the mean and plug in. If not, take the mean of all items weights, and plug in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Missing data treatment - *Item_Visibility*    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same approach as above: Find all visibility entries for the same product, take the mean, plug it in as the missing value. If no visibility entry is avaible, take the mean visibility of all items and plug it in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we are at it, let's look at the histogram of the visibility data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train.Item_Visibility, bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is skewed. We are going to take the square root of if to make it more normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUT049 0.060805543674193545\n",
      "OUT018 0.06101449825\n",
      "OUT010 0.10145735520540541\n",
      "OUT013 0.059956930729613736\n",
      "OUT027 0.05861472116898396\n",
      "OUT045 0.060474466806243264\n",
      "OUT017 0.061376507714902814\n",
      "OUT046 0.06046438195053763\n",
      "OUT035 0.06126330468709677\n",
      "OUT019 0.10844136560227273\n"
     ]
    }
   ],
   "source": [
    "for outlet in train.Outlet_Identifier.unique():\n",
    "    print(outlet, train[train.Outlet_Identifier==outlet].Item_Visibility.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items in OUT010 and OUT019 rated more visible than items in the other stores on avarage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supermarket Type1 0.06072282399802762\n",
      "Supermarket Type2 0.06101449825\n",
      "Grocery Store 0.10486230210249307\n",
      "Supermarket Type3 0.05861472116898396\n"
     ]
    }
   ],
   "source": [
    "for outlet in train.Outlet_Type.unique():\n",
    "    print(outlet, train[train.Outlet_Type==outlet].Item_Visibility.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Item_Visibility_Rate'] = 'Low'\n",
    "train.loc[(train.Outlet_Identifier == 'OUT010') | (train.Outlet_Identifier == 'OUT019'), 'Item_Visibility_Rate'] = 'High'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Missing data treatment - *Outlet_Size*    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlet has many other features. Maybe, I can use them to determine the size of outlets which are missing this entry.\n",
    "\n",
    "I am going to compute a simple cross tabulation of two factors. My goal is to take a look at the relationship between the *Outlet_Size* variable and the others. I am also going to use Chi-square statistics to determine if the relationship is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlet_Type  Grocery Store  Supermarket Type1  Supermarket Type2  \\\n",
      "Outlet_Size                                                        \n",
      "High                     0                932                  0   \n",
      "Medium                   0                930                928   \n",
      "Small                  528               1860                  0   \n",
      "\n",
      "Outlet_Type  Supermarket Type3  \n",
      "Outlet_Size                     \n",
      "High                         0  \n",
      "Medium                     935  \n",
      "Small                        0  \n",
      "Chi2 statistics p-value:  0.0\n",
      "------------------------------------------------------------\n",
      "Outlet_Location_Type  Tier 1  Tier 2  Tier 3\n",
      "Outlet_Size                                 \n",
      "High                       0       0     932\n",
      "Medium                   930       0    1863\n",
      "Small                   1458     930       0\n",
      "Chi2 statistics p-value:  0.0\n",
      "------------------------------------------------------------\n",
      "Outlet_Establishment_Year  1985  1987  1997  1999  2004  2009\n",
      "Outlet_Size                                                  \n",
      "High                          0   932     0     0     0     0\n",
      "Medium                      935     0     0   930     0   928\n",
      "Small                       528     0   930     0   930     0\n",
      "Chi2 statistics p-value:  0.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Outlet_Size vs. Outlet_Type\n",
    "tab = pd.crosstab(train.Outlet_Size, train.Outlet_Type)\n",
    "chi2, p, dof, ex = chi2_contingency(tab.values, correction=False)\n",
    "print(tab)\n",
    "print('Chi2 statistics p-value: ', p)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Outlet_Size vs. Outlet_Location_Type\n",
    "tab = pd.crosstab(train.Outlet_Size, train.Outlet_Location_Type)\n",
    "chi2, p, dof, ex = chi2_contingency(tab.values, correction=False)\n",
    "print(tab)\n",
    "print('Chi2 statistics p-value: ', p)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Outlet_Size vs. Outlet_Establishment_Year\n",
    "tab = pd.crosstab(train.Outlet_Size, train.Outlet_Establishment_Year)\n",
    "chi2, p, dof, ex = chi2_contingency(tab.values, correction=False)\n",
    "print(tab)\n",
    "print('Chi2 statistics p-value: ', p)\n",
    "print('------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there is no relationship between *Outlet_Size* and any of the other outlet features. I am going to take a closer look at the *Outlet_Type* and *Outlet_Location_Type* of the missing entries, and try to find a scheme to fill them by using the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlet_Location_Type  Tier 2  Tier 3\n",
      "Outlet_Type                         \n",
      "Grocery Store              0     555\n",
      "Supermarket Type1       1855       0\n"
     ]
    }
   ],
   "source": [
    "tab = pd.crosstab(train[train.Outlet_Size.isnull()].Outlet_Type, train[train.Outlet_Size.isnull()].Outlet_Location_Type)\n",
    "chi2, p, dof, ex = chi2_contingency(tab.values, correction=False)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the stores with missing Size values are either Grocery Stores with Tier 3 or Supermarket Type 1 with Tier 2. I am going to look at the rest of the data with the same pair combinations and see if they have the Size info avaiable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Small'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(~train.Outlet_Size.isnull()) & \\\n",
    "      (train.Outlet_Location_Type == 'Tier 2') & \\\n",
    "      (train.Outlet_Type == 'Supermarket Type1')].Outlet_Size.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(~train.Outlet_Size.isnull()) & \\\n",
    "      (train.Outlet_Location_Type == 'Tier 3') & \\\n",
    "      (train.Outlet_Type == 'Grocery Store')].Outlet_Size.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just figured out two things:\n",
    "- All Supermarket Type 1 - Tier 2 are Small in size. I will simply fill Small whereever I see this pair\n",
    "- There are no Grocery Stores - Tier 3 pair in the data. So I can't use the strategy I used above\n",
    "\n",
    "The only thing I can do at this point is I can look at all the Grocery Stores and see what size shows up the most frequent. Then, I will use that size to fill in the missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Small'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(~train.Outlet_Size.isnull()) & \\\n",
    "      (train.Outlet_Type == 'Grocery Store')].Outlet_Size.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are all Small size. \n",
    "\n",
    "**Strategy:** all of the missing values in the *Outlet_Size* variable will be ***Small***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Feature engineering - *Item_Identifier*    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two letters in Item_Identifier is a code that shows the category of the item. Let's see what these codes are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FD', 'DR', 'NC'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = train.Item_Identifier.apply(lambda x: x[:2])\n",
    "codes.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are 3 unique codes. Just to have an idea, let's see what type of items these codes are asscoiated with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    Dairy\n",
       "2                     Meat\n",
       "3    Fruits and Vegetables\n",
       "5             Baking Goods\n",
       "6              Snack Foods\n",
       "Name: Item_Type, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[codes == 'FD'].Item_Type.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     Soft Drinks\n",
       "18    Hard Drinks\n",
       "27    Hard Drinks\n",
       "34    Soft Drinks\n",
       "37    Soft Drinks\n",
       "Name: Item_Type, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[codes == 'DR'].Item_Type.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4              Household\n",
       "16    Health and Hygiene\n",
       "22             Household\n",
       "25             Household\n",
       "31    Health and Hygiene\n",
       "Name: Item_Type, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[codes == 'NC'].Item_Type.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not necessary to know the names of the categories for model building purposes, but it might be helpful to later interpret the model. For that reason, we are going to name them such that:\n",
    "- FD: Foods\n",
    "- DR: Drinks\n",
    "- NC: Non-consumables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy**:\n",
    "- Create a new feature called *Item_Category* and drop *Item_Identifier*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. Feature engineering - *Item_Fat_Content*    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are actually only two categories in this variable, sometimes the same category is represented by different names. I will fix that: \n",
    "\n",
    "**Strategy:**\n",
    "- Replace 'low fat' and 'LF' with 'Low Fat'\n",
    "- Replace 'reg' with 'Regular'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi. Feature engineering - *Outlet_Establishment_Year*    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new feature called *Outlet_Age* and drop the *Outlet_Establishment_Year*. The data was collected in 2013, so I will use 2013 as the current year.\n",
    "\n",
    "**Strategy:** \n",
    "- Outlet_Age = 2013 - Outlet_Establishment_Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vii. Feature engineering - *Item_MRP*    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the histogram of *Item_MRP* reveals that there are 4 distinct price categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train.Item_MRP, bins=200);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy:**\n",
    "\n",
    "I will create a new feauture called *Item_Price_Category* based on the following criteria:\n",
    "- MRP < 68 : Cheap\n",
    "- 68 < MRP < 135 : Affordable \n",
    "- 135 < MRP < 202 : Pricey \n",
    "- MRP > 202 : Expensive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to write custome transformations which will perform all the actions described above. These transformation will be added to pipeline and both training and test data will be pass through it. All transformers will accept pandas dataframe and return a dataframe. Let's start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first transformer will be called **SimpleColumnTransformer()** will handle the following tasks:\n",
    "- Create Item_Category variable\n",
    "- Fix Fat_Content variable\n",
    "- Create Outlet_Year variable\n",
    "- Create Item_Price_Category feature\n",
    "- Fill Outlet_Size variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleColumnTransformer(TransformerMixin):\n",
    "    '''\n",
    "    This class will perform 5 transformations. \n",
    "    By default, all 5 will be take place, but they can be skipped.\n",
    "    '''\n",
    "    def __init__(self, item_id=True, fat_content=True, outlet_year=True, item_mrp=True, outlet_size=True):\n",
    "        self.item_id = item_id\n",
    "        self.fat_content = fat_content\n",
    "        self.outlet_year = outlet_year\n",
    "        self.item_mrp = item_mrp\n",
    "        self.outlet_size = outlet_size\n",
    "        \n",
    "    def fit(self, X, y=None):  # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):  # assumes X is a DataFrame\n",
    "        if self.item_id:\n",
    "            X.loc[:, 'Item_Category'] = np.nan\n",
    "            codes = X['Item_Identifier'].apply(lambda x: x[:2])\n",
    "            X.loc[:, 'Item_Category'] = codes\n",
    "        \n",
    "        if self.fat_content:\n",
    "            X.Item_Fat_Content = X.Item_Fat_Content.replace(['low fat', 'LF'], 'Low Fat')\n",
    "            X.Item_Fat_Content = X.Item_Fat_Content.replace('reg', 'Regular')\n",
    "        \n",
    "        if self.outlet_year:\n",
    "            X.loc[:, 'Outlet_Age'] = 2013 - X.Outlet_Establishment_Year\n",
    "            X = X.drop('Outlet_Establishment_Year', axis=1)  # drop the redundant column\n",
    "            \n",
    "        if self.item_mrp:\n",
    "            X.loc[:, 'Item_Price_Category'] = np.nan  # create empty column first\n",
    "            X.loc[X.Item_MRP < 68, 'Item_Price_Category'] = 'Cheap'\n",
    "            X.loc[(X.Item_MRP > 68) & (X.Item_MRP < 135),'Item_Price_Category'] = 'Affordable'\n",
    "            X.loc[(X.Item_MRP > 135) & (X.Item_MRP < 202), 'Item_Price_Category'] = 'Pricey'\n",
    "            X.loc[X.Item_MRP > 202, 'Item_Price_Category'] = 'Expensive'\n",
    "        \n",
    "        if self.outlet_size:      \n",
    "            X.loc[(X.Outlet_Size.isnull()) & \\\n",
    "                  (X.Outlet_Location_Type == 'Tier 2') & \\\n",
    "                  (X.Outlet_Type == 'Supermarket Type1'), 'Outlet_Size'] = 'Small'\n",
    "\n",
    "            X.loc[(X.Outlet_Size.isnull()) & \\\n",
    "                  (X.Outlet_Location_Type == 'Tier 3') & \\\n",
    "                  (X.Outlet_Type == 'Grocery Store'), 'Outlet_Size'] = 'Small'       \n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second transformer will be called **TreatWeight()** and it will treat the missing data in Item_Weigth variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreatWeight(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        d = defaultdict(int)\n",
    "        for item in X.Item_Identifier:\n",
    "            replacement = X[(X.Item_Identifier == item) & (~X.Item_Weight.isnull())].Item_Weight.mean()\n",
    "            if math.isnan(replacement):\n",
    "                d[item] = X.Item_Weight.mean().round(2)\n",
    "            else:\n",
    "                d[item] = replacement.round(2)\n",
    "        self.weights = d\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        for index, item in X[X.Item_Weight.isnull()].Item_Identifier.iteritems():\n",
    "            X.loc[index, 'Item_Weight'] = self.weights[item]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third transformer will be called **TreatVisibility()** and it will treat the missing data in Item_Visibility variable and take the square root of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreatVisibility(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.visibs = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        d = defaultdict(int)\n",
    "        for item in X.Item_Identifier:\n",
    "            replacement = X[(X.Item_Identifier == item) & (X.Item_Visibility != 0.0)].Item_Visibility.mean()\n",
    "            if math.isnan(replacement):\n",
    "                d[item] = X.Item_Visibility.mean()\n",
    "            else:\n",
    "                d[item] = replacement\n",
    "        self.visibs = d\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        for index, item in X[X.Item_Visibility == 0.0].Item_Identifier.iteritems():\n",
    "            X.loc[index, 'Item_Visibility'] = self.visibs[item]\n",
    "        X.loc[:, 'Item_Visibility'] = np.sqrt(X.Item_Visibility)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forth transformer will be called **DummyTransformer()** and it will perform One_Hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        X = pd.get_dummies(X, drop_first=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fifth transformer will be called **ZeroOneScaler()** and it will perform Max Min Scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroOneScaler(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mm = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.mm = MinMaxScaler()\n",
    "        self.mm.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        X.loc[:,:] = self.mm.transform(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sixth and final transformer will be called **ColumnExtractor()** and it will return only selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        # assign columns\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xcols = X[self.cols]\n",
    "        return Xcols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the pipeline and fit the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['Item_Category', 'Item_Weight', 'Item_Fat_Content',\n",
    "             'Item_Visibility', 'Item_MRP', 'Item_Type', 'Item_Price_Category',\n",
    "             'Outlet_Type', 'Outlet_Location_Type', 'Outlet_Size', 'Outlet_Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('transform',\n",
       "                 <__main__.SimpleColumnTransformer object at 0x123169f98>),\n",
       "                ('weight', <__main__.TreatWeight object at 0x123169a90>),\n",
       "                ('visibility',\n",
       "                 <__main__.TreatVisibility object at 0x123169780>),\n",
       "                ('extract', <__main__.ColumnExtractor object at 0x1231699b0>),\n",
       "                ('dummy', <__main__.DummyTransformer object at 0x123169e48>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('transform', SimpleColumnTransformer()),\n",
    "            ('weight', TreatWeight()),\n",
    "            ('visibility', TreatVisibility()),\n",
    "            ('extract', ColumnExtractor(FEATURES)),\n",
    "            ('dummy', DummyTransformer())\n",
    "        ])\n",
    "\n",
    "pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 count  NaN  Unique\n",
      "Item_Weight                       8523    0     497\n",
      "Item_Visibility                   8523    0    8322\n",
      "Item_MRP                          8523    0    5938\n",
      "Outlet_Age                        8523    0       9\n",
      "Item_Category_FD                  8523    0       2\n",
      "Item_Category_NC                  8523    0       2\n",
      "Item_Fat_Content_Regular          8523    0       2\n",
      "Item_Type_Breads                  8523    0       2\n",
      "Item_Type_Breakfast               8523    0       2\n",
      "Item_Type_Canned                  8523    0       2\n",
      "Item_Type_Dairy                   8523    0       2\n",
      "Item_Type_Frozen Foods            8523    0       2\n",
      "Item_Type_Fruits and Vegetables   8523    0       2\n",
      "Item_Type_Hard Drinks             8523    0       2\n",
      "Item_Type_Health and Hygiene      8523    0       2\n",
      "Item_Type_Household               8523    0       2\n",
      "Item_Type_Meat                    8523    0       2\n",
      "Item_Type_Others                  8523    0       2\n",
      "Item_Type_Seafood                 8523    0       2\n",
      "Item_Type_Snack Foods             8523    0       2\n",
      "Item_Type_Soft Drinks             8523    0       2\n",
      "Item_Type_Starchy Foods           8523    0       2\n",
      "Item_Price_Category_Cheap         8523    0       2\n",
      "Item_Price_Category_Expensive     8523    0       2\n",
      "Item_Price_Category_Pricey        8523    0       2\n",
      "Outlet_Type_Supermarket Type1     8523    0       2\n",
      "Outlet_Type_Supermarket Type2     8523    0       2\n",
      "Outlet_Type_Supermarket Type3     8523    0       2\n",
      "Outlet_Location_Type_Tier 2       8523    0       2\n",
      "Outlet_Location_Type_Tier 3       8523    0       2\n",
      "Outlet_Size_Medium                8523    0       2\n",
      "Outlet_Size_Small                 8523    0       2\n"
     ]
    }
   ],
   "source": [
    "train_t = pipeline.transform(train)\n",
    "my_summary(train_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the data after transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Age</th>\n",
       "      <th>Item_Category_FD</th>\n",
       "      <th>Item_Category_NC</th>\n",
       "      <th>Item_Fat_Content_Regular</th>\n",
       "      <th>Item_Type_Breads</th>\n",
       "      <th>Item_Type_Breakfast</th>\n",
       "      <th>Item_Type_Canned</th>\n",
       "      <th>...</th>\n",
       "      <th>Item_Price_Category_Cheap</th>\n",
       "      <th>Item_Price_Category_Expensive</th>\n",
       "      <th>Item_Price_Category_Pricey</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Supermarket Type2</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "      <th>Outlet_Location_Type_Tier 2</th>\n",
       "      <th>Outlet_Location_Type_Tier 3</th>\n",
       "      <th>Outlet_Size_Medium</th>\n",
       "      <th>Outlet_Size_Small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.30</td>\n",
       "      <td>0.126678</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.92</td>\n",
       "      <td>0.138846</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.50</td>\n",
       "      <td>0.129461</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.20</td>\n",
       "      <td>0.151362</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.93</td>\n",
       "      <td>0.127139</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Visibility  Item_MRP  Outlet_Age  Item_Category_FD  \\\n",
       "0         9.30         0.126678  249.8092          14                 1   \n",
       "1         5.92         0.138846   48.2692           4                 0   \n",
       "2        17.50         0.129461  141.6180          14                 1   \n",
       "3        19.20         0.151362  182.0950          15                 1   \n",
       "4         8.93         0.127139   53.8614          26                 0   \n",
       "\n",
       "   Item_Category_NC  Item_Fat_Content_Regular  Item_Type_Breads  \\\n",
       "0                 0                         0                 0   \n",
       "1                 0                         1                 0   \n",
       "2                 0                         0                 0   \n",
       "3                 0                         1                 0   \n",
       "4                 1                         0                 0   \n",
       "\n",
       "   Item_Type_Breakfast  Item_Type_Canned  ...  Item_Price_Category_Cheap  \\\n",
       "0                    0                 0  ...                          0   \n",
       "1                    0                 0  ...                          1   \n",
       "2                    0                 0  ...                          0   \n",
       "3                    0                 0  ...                          0   \n",
       "4                    0                 0  ...                          1   \n",
       "\n",
       "   Item_Price_Category_Expensive  Item_Price_Category_Pricey  \\\n",
       "0                              1                           0   \n",
       "1                              0                           0   \n",
       "2                              0                           1   \n",
       "3                              0                           1   \n",
       "4                              0                           0   \n",
       "\n",
       "   Outlet_Type_Supermarket Type1  Outlet_Type_Supermarket Type2  \\\n",
       "0                              1                              0   \n",
       "1                              0                              1   \n",
       "2                              1                              0   \n",
       "3                              0                              0   \n",
       "4                              1                              0   \n",
       "\n",
       "   Outlet_Type_Supermarket Type3  Outlet_Location_Type_Tier 2  \\\n",
       "0                              0                            0   \n",
       "1                              0                            0   \n",
       "2                              0                            0   \n",
       "3                              0                            0   \n",
       "4                              0                            0   \n",
       "\n",
       "   Outlet_Location_Type_Tier 3  Outlet_Size_Medium  Outlet_Size_Small  \n",
       "0                            0                   1                  0  \n",
       "1                            1                   1                  0  \n",
       "2                            0                   1                  0  \n",
       "3                            1                   0                  1  \n",
       "4                            1                   0                  0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t = pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Build the predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to build multiple models and compare them. For this, I am going to split my training data (train_t) into training and validation sets. These sets will be used to evaluate the models' performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target variable\n",
    "target = train['Item_Outlet_Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no machine learning in Baseline solution. It is just a smart filling method. My strategy is as follows:\n",
    "- Identify the first item in test set and find its outlet_type and item_type\n",
    "- Go to training set, find all the instances of the same item having the same outlet_type\n",
    "- Take their mean. If it is a number, assign it as the prediction.\n",
    "- If there are no such instances, find the all instances with the same item_type and take their mean. Assign it as the prediction value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Baseline_Estimator(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.predicts = None\n",
    "\n",
    "    def fit(self, XX, y=None):\n",
    "        d = defaultdict(int)\n",
    "        for item in XX.Item_Identifier:\n",
    "            d[item] = XX[(XX.Item_Identifier == item)].Item_Outlet_Sales.mean()\n",
    "        self.predicts = d\n",
    "        return self\n",
    "\n",
    "    def predict(self, XX):\n",
    "        # assumes X is a DataFrame\n",
    "        for index, item in XX.Item_Identifier.iteritems():\n",
    "            XX.loc[index, 'Item_Outlet_Sales'] = self.predicts[item]\n",
    "        return XX.Item_Outlet_Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE =  1660.614220132992\n"
     ]
    }
   ],
   "source": [
    "base_model = Baseline_Estimator()\n",
    "base_model.fit(X_train)\n",
    "y_pred = base_model.predict(X_val)\n",
    "print(\"Baseline RMSE = \", np.sqrt(mean_squared_error(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Public dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "base_model = Baseline_Estimator()\n",
    "base_model.fit(train)\n",
    "test_target = base_model.predict(test)\n",
    "\n",
    "# Export for submission\n",
    "test.loc[:, 'Item_Otlet_Sales'] = test_target\n",
    "output = test[['Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales']]\n",
    "output.to_csv('baseline_solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After submitting the baseline solution, the score is:\n",
    "\n",
    "**(Public score) Baseline RMSE = 1598.68** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to split the transformed training data here. All the upcomming models will use the same set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the transformed data (output of pipeline)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_t, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Linear Regression with Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "estimator = LinearRegression()\n",
    "selector = RFECV(estimator, step=1, cv=3, min_features_to_select=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "Index(['Item_Visibility', 'Item_MRP', 'Outlet_Age', 'Item_Category_FD',\n",
      "       'Item_Category_NC', 'Item_Fat_Content_Regular', 'Item_Type_Breads',\n",
      "       'Item_Type_Breakfast', 'Item_Type_Canned', 'Item_Type_Dairy',\n",
      "       'Item_Type_Frozen Foods', 'Item_Type_Fruits and Vegetables',\n",
      "       'Item_Type_Hard Drinks', 'Item_Type_Health and Hygiene',\n",
      "       'Item_Type_Household', 'Item_Type_Meat', 'Item_Type_Others',\n",
      "       'Item_Type_Seafood', 'Item_Type_Snack Foods', 'Item_Type_Soft Drinks',\n",
      "       'Item_Type_Starchy Foods', 'Item_Price_Category_Cheap',\n",
      "       'Item_Price_Category_Expensive', 'Item_Price_Category_Pricey',\n",
      "       'Outlet_Type_Supermarket Type1', 'Outlet_Type_Supermarket Type2',\n",
      "       'Outlet_Type_Supermarket Type3', 'Outlet_Location_Type_Tier 2',\n",
      "       'Outlet_Location_Type_Tier 3', 'Outlet_Size_Medium',\n",
      "       'Outlet_Size_Small'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)\n",
    "print('Selected features:')\n",
    "print(train_t.columns[selector.support_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression with feature elimination RMSE =  1103.6581075533286\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = selector.predict(X_val)\n",
    "print(\"Linear Regression with feature elimination RMSE = \", np.sqrt(mean_squared_error(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "selector = selector.fit(train_t, target)\n",
    "test_target = selector.predict(test_t)\n",
    "\n",
    "# Export\n",
    "test['Item_Outlet_Sales'] = test_target\n",
    "output = test[['Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales']]\n",
    "output.to_csv('lr_rfecv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Public score) Linear Regression with feature elimination RMSE = 1202.72**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Random Forest with Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 1000],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 486 out of 486 | elapsed:  9.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF hyp. opt. RMSE =  1055.1096615622198\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_val)\n",
    "print(\"RF hyp. opt. RMSE = \", np.sqrt(mean_squared_error(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True, 'max_depth': 5, 'min_samples_leaf': 4, 'n_estimators': 400}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Item_Weight',\n",
       " 'Item_Visibility',\n",
       " 'Item_MRP',\n",
       " 'Outlet_Age',\n",
       " 'Item_Price_Category_Expensive',\n",
       " 'Item_Price_Category_Pricey',\n",
       " 'Outlet_Type_Supermarket Type1',\n",
       " 'Outlet_Type_Supermarket Type2',\n",
       " 'Outlet_Type_Supermarket Type3',\n",
       " 'Outlet_Size_Medium',\n",
       " 'Outlet_Size_Small']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = X_train.columns.values\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "important_features = [features[i] for i, imp in enumerate(importances) if imp > 0.001]\n",
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF hyp. opt. w/ feat. sel. RMSE =  1055.9962129317746\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "rf = RandomForestRegressor(max_depth=5, min_samples_leaf=4, n_estimators=100, random_state=42)\n",
    "rf.fit(X_train[important_features], y_train)\n",
    "\n",
    "y_pred = rf.predict(X_val[important_features])\n",
    "print(\"RF hyp. opt. w/ feat. sel. RMSE = \", np.sqrt(mean_squared_error(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(!) Eliminating extra features did not improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Public dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "rf.fit(train_t[important_features], target)\n",
    "test_target = rf.predict(test_t[important_features])\n",
    "\n",
    "# Export\n",
    "test['Item_Outlet_Sales'] = test_target\n",
    "output = test[['Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales']]\n",
    "output.to_csv('rf_opt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Public score) Random Forest with hyp. opt. RMSE = 1152.87**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "RMSE: 1160.838296\n",
      "Test: 0.5192018616686835\n",
      "Train: 0.510490531731213\n",
      "2\n",
      "RMSE: 1081.850445\n",
      "Test: 0.5824064528995557\n",
      "Train: 0.5897337467292103\n",
      "3\n",
      "RMSE: 1061.903953\n",
      "Test: 0.5976631627068683\n",
      "Train: 0.6222895799344221\n",
      "4\n",
      "RMSE: 1061.438149\n",
      "Test: 0.5980160550685669\n",
      "Train: 0.6460898298819107\n",
      "5\n",
      "RMSE: 1064.835118\n",
      "Test: 0.5954389629480101\n",
      "Train: 0.6726656160156788\n",
      "6\n",
      "RMSE: 1071.080403\n",
      "Test: 0.5906795244477605\n",
      "Train: 0.7083850581879783\n",
      "7\n",
      "RMSE: 1079.857821\n",
      "Test: 0.583943339646801\n",
      "Train: 0.7463497306484315\n",
      "8\n",
      "RMSE: 1088.994996\n",
      "Test: 0.5768726564960911\n",
      "Train: 0.7894435645706\n",
      "9\n",
      "RMSE: 1098.307415\n",
      "Test: 0.5696050625078345\n",
      "Train: 0.8287773376223277\n",
      "10\n",
      "RMSE: 1104.393786\n",
      "Test: 0.5648216992713977\n",
      "Train: 0.8593659152416984\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree=0.3, learning_rate=0.1,\n",
    "                max_depth=1, alpha=10, n_estimators=100, booster='gbtree')\n",
    "\n",
    "for i in range(1,11):\n",
    "    xg_reg.set_params(max_depth=i)\n",
    "    xg_reg.fit(X_train, y_train)\n",
    "    y_pred = xg_reg.predict(X_val)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    print(i)\n",
    "    print(\"RMSE: %f\" % (rmse))\n",
    "    print('Test:', r2_score(y_val, y_pred))\n",
    "    print('Train:', r2_score(y_train, xg_reg.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal max_depth is 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "RMSE: 1453.030478\n",
      "Test: 0.24669860693426338\n",
      "Train: 0.21352559650290326\n",
      "20\n",
      "RMSE: 1184.415185\n",
      "Test: 0.4994732915791157\n",
      "Train: 0.4854732492968412\n",
      "30\n",
      "RMSE: 1101.239457\n",
      "Test: 0.5673040301064218\n",
      "Train: 0.5666178293774524\n",
      "40\n",
      "RMSE: 1075.829013\n",
      "Test: 0.5870420539082549\n",
      "Train: 0.5950895173054211\n",
      "50\n",
      "RMSE: 1062.367009\n",
      "Test: 0.5973121985309007\n",
      "Train: 0.6128186187478392\n",
      "60\n",
      "RMSE: 1059.846879\n",
      "Test: 0.5992204313354104\n",
      "Train: 0.6222275894074634\n",
      "70\n",
      "RMSE: 1059.242399\n",
      "Test: 0.5996774671664933\n",
      "Train: 0.6305362795616825\n",
      "80\n",
      "RMSE: 1058.777890\n",
      "Test: 0.6000284971898948\n",
      "Train: 0.6376172795698607\n",
      "90\n",
      "RMSE: 1060.119704\n",
      "Test: 0.5990140680043802\n",
      "Train: 0.6410912880921313\n",
      "100\n",
      "RMSE: 1061.438149\n",
      "Test: 0.5980160550685669\n",
      "Train: 0.6460898298819107\n"
     ]
    }
   ],
   "source": [
    "xg_reg.set_params(max_depth=4);\n",
    "\n",
    "for i in range(10,110,10):\n",
    "    xg_reg.set_params(n_estimators=i)\n",
    "    xg_reg.fit(X_train, y_train)\n",
    "    y_pred = xg_reg.predict(X_val)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    print(i)\n",
    "    print(\"RMSE: %f\" % (rmse))\n",
    "    print('Test:', r2_score(y_val, y_pred))\n",
    "    print('Train:', r2_score(y_train, xg_reg.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal n_estimators is 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost RMSE =  1058.7778896684076\n"
     ]
    }
   ],
   "source": [
    "xg_reg.set_params(n_estimators=80)\n",
    "xg_reg.fit(X_train, y_train)\n",
    "y_pred = xg_reg.predict(X_val)\n",
    "print(\"XGBoost RMSE = \", np.sqrt(mean_squared_error(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Public dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "xg_reg.fit(train_t, target)\n",
    "test_target = xg_reg.predict(test_t)\n",
    "\n",
    "# Export\n",
    "test['Item_Outlet_Sales'] = test_target\n",
    "output = test[['Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales']]\n",
    "output.to_csv('xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Public score) XGBoost RMSE = 1152.84**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
